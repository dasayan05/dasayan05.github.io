---
title: 'BézierSketch: A generative model for scalable vector sketches'
publish: true
author: Ayan Das
authors: <i>Ayan Das</i>, Yongxin Yang, Timothy Hospedales, Tao Xiang, Yi-Zhe Song
venue: European Conference on Computer Vision (ECCV), 2020
link: https://arxiv.org/abs/2007.02190
date: 2020-07-03
tags:
    - Generative Model
    - Sketch Synthesis
    - Bézier Curves
layout: pub
post_number: "7"
related_post_numbers: ""
comments: false
category: pubs
thumbnail-img: public/pub_res/7.png
---

The study of neural generative models of human sketches is a fascinating contemporary modeling problem due to the links between sketch image generation and the human drawing process. The landmark SketchRNN provided breakthrough by sequentially generating sketches as a sequence of waypoints. However this  leads to low-resolution image generation, and failure to model long sketches. In this paper we present BézierSketch, a novel generative model for fully vector sketches that are automatically scalable and high-resolution. To this end, we first introduce a novel inverse graphics approach to stroke embedding that trains an encoder to embed each stroke to its best fit Bézier curve. This enables us to treat sketches as short sequences of paramaterized strokes and thus train a recurrent sketch generator with greater capacity for longer sketches, while producing scalable high-resolution results. We report qualitative and quantitative results on the Quick, Draw! benchmark.

```
@misc{das2020bziersketch,
    title={BézierSketch: A generative model for scalable vector sketches},
    author={Ayan Das and Yongxin Yang and Timothy Hospedales and Tao Xiang and Yi-Zhe Song},
    year={2020},
    eprint={2007.02190},
    archivePrefix={arXiv},
    primaryClass={cs.CV}
}
```